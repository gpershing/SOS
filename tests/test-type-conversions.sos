/*bool to int*/
//Type conversion during variable assignment
x: bool = true
y: int = x
y = x + 9
print(y) //10

//Type conversion during function application
sum: (x: int, y: int) -> int = x + y
summed: int = sum(true, false)
print(summed) //1


/*int to bool*/
//Type conversion during variable assignment
m: int = 1
n: int = 0
o: bool = m 
p: bool = n
print(o) //True
print(p) //False

//Type conversion based on unary operator
p = !1
print(p) //False

//Type conversion during function application
not: (x: bool) -> bool = !x
notted: bool  = not(1)
print(notted) //False


/*float to int (via truncation) */
a: float = -0.5
b: int = a
print(b) //0

a = 2.9
b = a
print(b) //2

a = -2.9
b = a
print(b) //-2


/*float to bool: anything other than 0.0 is true */
b: bool = 1.1 //1
print(b)
b = -1.1 //1
print(b)
b = 0.1
print(b) //1
b = 0.0
print(b) // 0

//Type conversion during function application (use sum() on line 15)
summed2: int = sum(1.2, 3.5)
print(summed2) //4


/*int to float (via injection) */
c: int = 2
d: float = c
printf(d) //2.0

//Type conversion during function application
floatsum: (x: float, y: float) -> float = x + y
e: float = floatsum(1, 2)
printf(e) //3.0
